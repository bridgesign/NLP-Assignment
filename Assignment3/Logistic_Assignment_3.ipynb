{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Assignment 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2N8Z4de5fW-",
        "colab_type": "code",
        "outputId": "624e5f49-2a9d-4b58-80cc-6f64a1688932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "datapath = '/content/gdrive/My Drive/NLP/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SnBxEhe5-2g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "ee9f919a-1b25-4eab-e59d-c0e2c656a4bc"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Concatenate, Input, Reshape, Conv2D, Dropout, Conv1D, CuDNNLSTM, CuDNNGRU, Bidirectional\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "from keras.layers.core import *\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import LSTM, SimpleRNN, GRU\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from collections import defaultdict\n",
        "import keras.backend as K\n",
        "from keras import optimizers\n",
        "import keras\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZDgF60C54tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_data(file):\n",
        "  text = file.read()\n",
        "  fields = ['#','$','%', '^','&','*','@','/','//','\\\\','[',']','(',')', 'https','http','.','co','....','..']\n",
        "  entries = [j.split('\\n') for j in text.split('\\n\\n')]\n",
        "  data = {'text':[], 'lang':[], 'tag':[]}\n",
        "  for entry in entries:\n",
        "    sent = entry[0].split('\\t')[-1]\n",
        "    if sent == 'positive':\n",
        "      data['tag'].append(0)\n",
        "    elif sent=='negative':\n",
        "      data['tag'].append(1)\n",
        "    else:\n",
        "      data['tag'].append(2)\n",
        "    words = []\n",
        "    langs = []\n",
        "    for wordl in entry[1:]:\n",
        "      word, lang = wordl.split('\\t')\n",
        "      try:\n",
        "        if word not in fields and word[0] not in fields:\n",
        "          words.append(word)\n",
        "          langs.append(lang)\n",
        "      except:\n",
        "        print(word)\n",
        "        break\n",
        "    data['text'].append(' '.join(words))\n",
        "    data['lang'].append(' '.join(langs))\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-moS7h_8QJq",
        "colab_type": "code",
        "outputId": "279bce06-159d-4c81-f678-3c4ff4bad210",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "with open(datapath+'train.txt', 'r') as f:\n",
        "  trainval = create_data(f)\n",
        "with open(datapath+'test.txt', 'r') as f:\n",
        "  test = create_data(f)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6-MAOb_-f_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.DataFrame(test)\n",
        "trainval = pd.DataFrame(trainval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyYkNTSJ957D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SPLIT = 0.1\n",
        "MAXLEN_WORD = 128\n",
        "MAXLEN_SENT = 64\n",
        "EMB_FEATURES = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkFXNeH091bA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val = train_test_split(trainval, test_size = SPLIT, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY1b-Fdo8-Yl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_lang = Tokenizer(num_words=4, filters='')\n",
        "tokenizer_lang.fit_on_texts(train['lang'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EaOxoDF_bOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer_text = Tokenizer(num_words=EMB_FEATURES+3, filters='', char_level=True)\n",
        "tokenizer_text.fit_on_texts(train['text'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrOWzBev9YEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_3d_data(data, tokenizer_text, tokenizer_lang, MAXLEN_WORD, MAXLEN_SENT):\n",
        "  vectorizer = TfidfVectorizer(max_features=5000)\n",
        "  X_text = vectorizer.fit_transform(data['text'])\n",
        "  X_lang = sequence.pad_sequences(tokenizer_lang.texts_to_sequences(data['lang']), maxlen=MAXLEN_SENT)\n",
        "  Y = np.array(data['tag'])\n",
        "  return X_text, X_lang, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNy_X5GgPmxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_text_train, X_lang_train, Y_train = create_3d_data(train, tokenizer_text, tokenizer_lang, MAXLEN_WORD, MAXLEN_SENT)\n",
        "X_text_val, X_lang_val, Y_val = create_3d_data(val, tokenizer_text, tokenizer_lang, MAXLEN_WORD, MAXLEN_SENT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QbzRo7wY9vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_text_test, X_lang_test, Y_test = create_3d_data(test, tokenizer_text, tokenizer_lang, MAXLEN_WORD, MAXLEN_SENT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnDzJG8jQrmY",
        "colab_type": "code",
        "outputId": "c9d6856e-8ffe-452b-946c-ddd424940daa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(X_text_train.shape, X_lang_train.shape, Y_train.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13618, 5000) (13618, 64) (13618,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eq_i6qg6a1p1",
        "colab_type": "code",
        "outputId": "00c87047-30fb-458b-db41-e23f1c1fa7d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(X_text_test.shape, X_lang_test.shape, Y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1870, 5000) (1870, 64) (1870,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbSg3GTeRYZR",
        "colab_type": "code",
        "outputId": "f225eefe-f01d-46a6-9acf-11cb91aa5821",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.max(X_text_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuDhB0gTcvKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB6R5yj_cvIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgR0bSNxcvHJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "4970a27f-5d07-4a0a-8030-17333ab7e1d2"
      },
      "source": [
        "logreg.fit(X_text_train, Y_train)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
            "  \"of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
              "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
              "                   max_iter=100, multi_class='multinomial', n_jobs=None,\n",
              "                   penalty='l2', random_state=None, solver='lbfgs', tol=0.0001,\n",
              "                   verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRCnEb0tenkj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "def cal_accuracy(y_test, y_pred): \n",
        "      \n",
        "    print(\"Confusion Matrix: \\n\", \n",
        "        confusion_matrix(y_test, y_pred)) \n",
        "      \n",
        "    print (\"Accuracy : \", \n",
        "    accuracy_score(y_test,y_pred)*100) \n",
        "      \n",
        "    print(\"Report \\n: \", \n",
        "    classification_report(y_test, y_pred)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuqH001tcvES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = logreg.predict(X_text_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IY0GVgTZcvB_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "f69806be-02e4-4b87-cdf8-8639f57ab647"
      },
      "source": [
        "cal_accuracy(Y_val, pred)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            " [[189 120 160]\n",
            " [213  92 165]\n",
            " [238 135 202]]\n",
            "Accuracy :  31.90224570673712\n",
            "Report \n",
            ":                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.30      0.40      0.34       469\n",
            "           1       0.27      0.20      0.23       470\n",
            "           2       0.38      0.35      0.37       575\n",
            "\n",
            "    accuracy                           0.32      1514\n",
            "   macro avg       0.31      0.32      0.31      1514\n",
            "weighted avg       0.32      0.32      0.31      1514\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfM4CJIZcu_M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = logreg.predict(X_text_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKvRaq3Scu8i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "83bba322-38bf-41cc-a440-981ead3a5ca8"
      },
      "source": [
        "cal_accuracy(Y_test, pred)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            " [[152 110 320]\n",
            " [155  92 286]\n",
            " [230 140 385]]\n",
            "Accuracy :  33.63636363636363\n",
            "Report \n",
            ":                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.26      0.27       582\n",
            "           1       0.27      0.17      0.21       533\n",
            "           2       0.39      0.51      0.44       755\n",
            "\n",
            "    accuracy                           0.34      1870\n",
            "   macro avg       0.31      0.31      0.31      1870\n",
            "weighted avg       0.32      0.34      0.32      1870\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
