{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T_Assignment 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2N8Z4de5fW-",
        "colab_type": "code",
        "outputId": "875597bb-9a0c-4340-9f5e-f20ba46207f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "datapath = '/content/gdrive/My Drive/NLP/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SnBxEhe5-2g",
        "colab_type": "code",
        "outputId": "1b95ecc4-869c-4257-de43-6eb0d0f9d7c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.utils import np_utils\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3SchbTtlpNd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jd_TAOm1lzgb",
        "colab_type": "code",
        "outputId": "8857032f-ca2d-4ef5-d9b1-2e5b20408b5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert pytorch-nlp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4f/51/f0ee1efb75f7cc2e3065c5da1363d6be2eec79691b2821594f3f2329528c/pytorch_nlp-0.5.0-py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.1+cu100)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.10.14)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.14 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.13.14)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.14->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: regex, pytorch-pretrained-bert, pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2 regex-2019.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgNAATqll6BH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "from tqdm import tqdm, trange\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-N5QRLzmB-N",
        "colab_type": "code",
        "outputId": "aeadfc29-54d8-4ddb-9111-8f412b27c554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# specify GPU device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZDgF60C54tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_data(file):\n",
        "  text = file.read()\n",
        "  fields = ['#','$','%', '^','&','*','@','/','//','\\\\','[',']','(',')', 'https','http','.','co','....','..']\n",
        "  entries = [j.split('\\n') for j in text.split('\\n\\n')]\n",
        "  data = {'text':[], 'lang':[], 'tag':[]}\n",
        "  for entry in entries:\n",
        "    sent = entry[0].split('\\t')[-1]\n",
        "    if sent == 'positive':\n",
        "      data['tag'].append(0)\n",
        "    elif sent=='negative':\n",
        "      data['tag'].append(1)\n",
        "    else:\n",
        "      data['tag'].append(2)\n",
        "    words = []\n",
        "    langs = []\n",
        "    for wordl in entry[1:]:\n",
        "      word, lang = wordl.split('\\t')\n",
        "      if word not in fields and word[0] not in fields:\n",
        "        words.append(word)\n",
        "        langs.append(lang)\n",
        "    data['text'].append('[CLS] '+' '.join(words)+' [SEP]')\n",
        "    data['lang'].append(langs)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-moS7h_8QJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(datapath+'train.txt', 'r') as f:\n",
        "  trainval = create_data(f)\n",
        "with open(datapath+'test.txt', 'r') as f:\n",
        "  test = create_data(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6-MAOb_-f_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.DataFrame(test)\n",
        "trainval = pd.DataFrame(trainval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyYkNTSJ957D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SPLIT = 0.1\n",
        "MAXLEN_WORD = 128\n",
        "MAXLEN_SENT = 178\n",
        "EMB_FEATURES = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_MLsXfymrB-",
        "colab_type": "code",
        "outputId": "77a757f2-8765-4162-9025-3f998f4866a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>lang</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[CLS] RT UAAPconfessions Love looks good on Ma...</td>\n",
              "      <td>[Eng, Eng, Eng, Eng, Eng, Eng, Eng, O, Eng, En...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[CLS] Ye Ye ..... ye ??????? We gonna start an...</td>\n",
              "      <td>[Hin, Hin, O, Hin, O, Hin, Hin, Eng, Eng, Eng,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[CLS] zWffFY9JGklElA1 Min _ Of _ Lyching thaku...</td>\n",
              "      <td>[Eng, Eng, O, Hin, O, Eng, Eng, Eng, Hin, Hin,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[CLS] ~ Caring . ~ Bohot Jyada Caring . ~ Cour...</td>\n",
              "      <td>[O, Eng, O, O, Hin, Hin, Eng, O, O, Eng, Eng, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[CLS] AliHZaidiPTI SarfarazA _ 54 What nonesen...</td>\n",
              "      <td>[Hin, Hin, O, O, Hin, Eng, O, Hin, Hin, Eng, H...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1865</th>\n",
              "      <td>[CLS] AmnaKhanPMLN 1992 ma Duain kabool hui th...</td>\n",
              "      <td>[Hin, O, Hin, Hin, Hin, Hin, Hin, Hin, Hin, Hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1866</th>\n",
              "      <td>[CLS] javerias Jo harami video bna rha he ye a...</td>\n",
              "      <td>[Eng, Hin, Hin, Hin, Hin, Hin, Hin, Hin, Hin, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867</th>\n",
              "      <td>[CLS] RT falasizz FUCK MS THORPE FUCK MS BAAJ ...</td>\n",
              "      <td>[Hin, Hin, Eng, Hin, Hin, Eng, Hin, Hin, Eng, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1868</th>\n",
              "      <td>[CLS] jigneshmevani80 dgpgujarat AhmedabadPoli...</td>\n",
              "      <td>[Eng, Eng, Hin, Hin, Hin, Hin, Hin, Hin, Hin, ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1869</th>\n",
              "      <td>[CLS]  [SEP]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1870 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  ... tag\n",
              "0     [CLS] RT UAAPconfessions Love looks good on Ma...  ...   2\n",
              "1     [CLS] Ye Ye ..... ye ??????? We gonna start an...  ...   2\n",
              "2     [CLS] zWffFY9JGklElA1 Min _ Of _ Lyching thaku...  ...   2\n",
              "3     [CLS] ~ Caring . ~ Bohot Jyada Caring . ~ Cour...  ...   1\n",
              "4     [CLS] AliHZaidiPTI SarfarazA _ 54 What nonesen...  ...   0\n",
              "...                                                 ...  ...  ..\n",
              "1865  [CLS] AmnaKhanPMLN 1992 ma Duain kabool hui th...  ...   0\n",
              "1866  [CLS] javerias Jo harami video bna rha he ye a...  ...   2\n",
              "1867  [CLS] RT falasizz FUCK MS THORPE FUCK MS BAAJ ...  ...   1\n",
              "1868  [CLS] jigneshmevani80 dgpgujarat AhmedabadPoli...  ...   1\n",
              "1869                                       [CLS]  [SEP]  ...   2\n",
              "\n",
              "[1870 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIUJCtnDmSIb",
        "colab_type": "code",
        "outputId": "41a32e4b-c7fe-4bf4-caed-be7f2ce8fe83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 871891/871891 [00:00<00:00, 957193.24B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBqTPSVC3fqC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in trainval['text']]\n",
        "# Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAXLEN_SENT, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfS94M8VQGjW",
        "colab_type": "code",
        "outputId": "73e553a6-82d2-4077-d2d7-8d250a2e0c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "input_ids[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101, 81393, 12905, 10370, 20781, 10123, 14897, 10237, 23550,\n",
              "       10281, 16387, 11561, 10191, 14897, 12847, 11236, 17439, 25745,\n",
              "       10150, 18114, 10262, 25275, 10211, 10127, 10457, 30646, 11009,\n",
              "       31340, 10191,   118, 27895, 30646,   102,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbGvmaK53mc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in input_ids:\n",
        "  seq_mask = [float(i>0) for i in seq]\n",
        "  attention_masks.append(seq_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R2Ypg_x326E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, [[j] for j in trainval['tag']], \n",
        "                                                            random_state=2018, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                             random_state=2018, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoqxEchK4InS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert all of our data into torch tensors, the required datatype for our model\n",
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "# Select a batch size for training. \n",
        "batch_size = 16\n",
        "\n",
        "# Create an iterator of our data with torch DataLoader \n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4K7wuCf5QH8",
        "colab_type": "code",
        "outputId": "b3ba222e-44d5-40c9-cea5-1da23bf0c5e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-uncased\", num_labels=3)\n",
        "model.cuda()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 623743758/623743758 [07:10<00:00, 1449815.68B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vOyErsbV7dS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recall_m(y_pred, y_true):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "def precision_m(y_pred, y_true):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "\n",
        "def f1_m(y_pred, y_true):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmfTylYCpRKo",
        "colab_type": "code",
        "outputId": "ff8edc6d-c320-4057-c39d-a6399114ce7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# BERT fine-tuning parameters\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=2e-5,\n",
        "                     warmup=.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d98Yckrf6AEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store our loss and accuracy for plotting\n",
        "train_loss_set = []\n",
        "# Number of training epochs \n",
        "epochs = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpQn72Lj6Gef",
        "colab_type": "code",
        "outputId": "1c9346c1-83f4-4286-8f08-e8965af56182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "# BERT training loop\n",
        "for _ in trange(epochs, desc=\"Epoch\"):  \n",
        "  \n",
        "  ## TRAINING\n",
        "  \n",
        "  # Set our model to training mode\n",
        "  model.train()  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Clear out the gradients (by default they accumulate)\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask.long(), labels=b_labels)\n",
        "    train_loss_set.append(loss.item())    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    # Update tracking variables\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "       \n",
        "  ## VALIDATION\n",
        "\n",
        "  # Put model in evaluation mode\n",
        "  model.eval()\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy, eval_f1, eval_precision, eval_recall = 0, 0, 0, 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask.long())    \n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)    \n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    #eval_f1 += f1_m(logits, label_ids)\n",
        "    #eval_recall += recall_m(logits, label_ids)\n",
        "    #eval_precision += precision_m(logits, label_ids)\n",
        "    nb_eval_steps += 1\n",
        "  #print(\"Val_Accuracy: {} Val_f1: {} Val_recall: {} Val_precision: {}\".format(eval_accuracy/nb_eval_steps,eval_f1/nb_eval_steps,eval_recall/nb_eval_steps,eval_precision/nb_eval_steps))\n",
        "  print(\"Val_Accuracy: {}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 1.099630741446231\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:  25%|██▌       | 1/4 [17:10<51:31, 1030.47s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val_Accuracy: 0.37552631578947365\n",
            "Train loss: 1.0945798625968433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:  50%|█████     | 2/4 [34:22<34:21, 1030.94s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Val_Accuracy: 0.37552631578947365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Alqj1J567HK",
        "colab_type": "code",
        "outputId": "26bce1a6-cd51-40bc-818e-e79228ff15d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "# plot training performance\n",
        "plt.figure(figsize=(15,8))\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Batch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.plot(train_loss_set)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAHwCAYAAAD0Es3SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 1080x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdFbcPEMFOCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}